{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a2a798370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_id, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"{}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
      "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "      super(Net, self).__init__()\n",
    "\n",
    "      # First 2D convolutional layer, taking in 1 input channel (image),\n",
    "      # outputting 10 convolutional features, with a square kernel size of 5\n",
    "      self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "      # Second 2D convolutional layer, taking in the 10 input layers,\n",
    "      # outputting 20 convolutional features, with a square kernel size of 3\n",
    "      self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "\n",
    "        \n",
    "      # Designed to ensure that adjacent pixels are either all 0s or all active\n",
    "      # with an input probability\n",
    "      self.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "      # First fully connected layer\n",
    "      self.fc1 = nn.Linear(320, 50)\n",
    "      # Second fully connected layer that outputs our 10 labels\n",
    "      self.fc2 = nn.Linear(50, 10)\n",
    "        # expected 5000 (50 * 10), 320\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "\n",
    "network = Net()\n",
    "print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "  network.train()\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))\n",
    "      train_losses.append(loss.item())\n",
    "      train_counter.append(\n",
    "        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n",
    "#       torch.save(network.state_dict(), './results/model.pth')\n",
    "#       torch.save(optimizer.state_dict(), './results/optimizer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  test_losses.append(test_loss)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/data-visualization/lib/python3.7/site-packages/ipykernel_launcher.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3055, Accuracy: 1287/10000 (13%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.315726\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.323595\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.317707\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.318412\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.356097\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.369715\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.288597\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.347165\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.364356\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.351144\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.302477\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.319450\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.290553\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.265286\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.270542\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.301897\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.287222\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.334852\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 2.327018\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 2.338845\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.331832\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 2.330559\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 2.244491\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 2.357489\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 2.340424\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.305114\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.313424\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 2.295277\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 2.270499\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 2.303867\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.324525\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 2.304894\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 2.274150\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 2.353340\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 2.325233\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.328556\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 2.300854\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 2.378620\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 2.398860\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 2.310781\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.333285\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 2.360595\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 2.287639\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 2.293322\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 2.344292\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.307173\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 2.328075\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 2.298886\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 2.317065\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 2.272850\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 2.338778\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 2.335010\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 2.345877\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 2.337931\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 2.343356\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.334646\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 2.320035\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 2.349329\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 2.340278\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 2.372591\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 2.297136\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 2.305790\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 2.301513\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 2.332059\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 2.340159\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 2.324664\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 2.348616\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 2.330474\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 2.338040\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 2.347461\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 2.334586\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 2.330735\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 2.344052\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 2.315196\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 2.327741\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 2.330095\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 2.295620\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 2.351487\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 2.371222\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 2.283277\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 2.340914\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 2.376939\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 2.313631\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 2.319575\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 2.320272\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.346773\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 2.345969\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 2.322742\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 2.291631\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 2.334685\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 2.307796\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 2.305260\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 2.293474\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 2.325259\n",
      "\n",
      "Test set: Avg. loss: 2.3055, Accuracy: 1287/10000 (13%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.357010\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 2.302994\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 2.358734\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 2.310176\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 2.302127\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 2.289790\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 2.272005\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 2.311663\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 2.309708\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 2.308033\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 2.309420\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 2.305923\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 2.313329\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 2.299143\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 2.310669\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 2.329341\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 2.322552\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 2.329795\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 2.315458\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 2.319720\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 2.384085\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 2.305174\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 2.266550\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 2.391417\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 2.313549\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 2.312698\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 2.311722\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 2.368135\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 2.333461\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 2.331829\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 2.351114\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 2.306806\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 2.349439\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 2.297431\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 2.331861\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 2.293930\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 2.339046\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 2.351484\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 2.291304\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 2.304007\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 2.299181\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 2.335992\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 2.319452\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 2.299692\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 2.295783\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 2.280299\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 2.308225\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 2.328743\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 2.342331\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 2.318772\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 2.345559\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 2.345727\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 2.305641\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 2.248267\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 2.280010\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 2.337856\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 2.294814\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 2.306517\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 2.330973\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 2.310452\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 2.333704\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 2.345751\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 2.322017\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 2.395420\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 2.272083\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 2.279672\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 2.306284\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 2.299089\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 2.305105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 2.288895\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 2.293000\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 2.344549\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 2.316699\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 2.276683\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 2.374560\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 2.281632\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 2.306222\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 2.299673\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 2.294724\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 2.298490\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 2.316360\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 2.346789\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 2.336747\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 2.328973\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 2.366712\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 2.334711\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 2.361502\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 2.325881\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 2.325577\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 2.280251\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 2.301936\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 2.340120\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 2.322042\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 2.280999\n",
      "\n",
      "Test set: Avg. loss: 2.3055, Accuracy: 1287/10000 (13%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.394913\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 2.323132\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 2.293481\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 2.332811\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 2.379146\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 2.314586\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 2.285713\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 2.278785\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 2.319868\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 2.377183\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 2.312307\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 2.318182\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 2.302659\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 2.339562\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 2.267429\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 2.281500\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 2.315360\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 2.293470\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 2.340408\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 2.328864\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 2.316262\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 2.284008\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 2.364139\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 2.324552\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 2.309134\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 2.324593\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 2.329774\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 2.412941\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 2.362131\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 2.297149\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 2.353946\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 2.369040\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 2.349793\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 2.321286\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 2.382485\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 2.329782\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 2.350144\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 2.346353\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 2.337717\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 2.265108\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 2.312651\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 2.340795\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 2.280788\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 2.332278\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 2.308927\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 2.302291\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 2.328905\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 2.314362\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 2.286668\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 2.307403\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 2.309231\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 2.331409\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 2.315599\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 2.326635\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 2.320498\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 2.318328\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 2.327322\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 2.301014\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 2.336017\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 2.307505\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 2.336199\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 2.355921\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 2.339743\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 2.351782\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 2.317476\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 2.357501\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 2.278665\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 2.338507\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 2.325866\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 2.318866\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 2.293819\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 2.316088\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 2.321650\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 2.335792\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 2.397067\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 2.271752\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 2.330178\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 2.281093\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 2.370200\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 2.336572\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 2.294716\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 2.339133\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 2.323729\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 2.359369\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 2.282330\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 2.337048\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 2.311358\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 2.281662\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 2.375365\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 2.330230\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 2.274635\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 2.280228\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 2.334198\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 2.334243\n",
      "\n",
      "Test set: Avg. loss: 2.3055, Accuracy: 1287/10000 (13%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch)\n",
    "  test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
